{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import struct \n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这是客户端本地项目路径  映射到   /code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD\t\t     cifar10_input_test.py\t __init__.py\r\n",
      "cifar-10-batches-py  cifar10_log\t\t predict.es.ipynb\r\n",
      "cifar10_data\t     cifar10_multi_gpu_train.py  __pycache__\r\n",
      "cifar10_eval\t     cifar10.py\t\t\t README.md\r\n",
      "cifar10_eval.py      cifar10_train\t\t train.cifar.ipynb\r\n",
      "cifar10_input.py     cifar10_train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches.meta.txt  data_batch_2.bin  data_batch_4.bin  readme.html\r\n",
      "data_batch_1.bin  data_batch_3.bin  data_batch_5.bin  test_batch.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls cifar10_data/cifar-10-batches-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先下载数据库\n",
    "     客户端执行  polyaxon run -f job.yml  然后会在  虚拟主机/data/mnist在有数据文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  数据路径存在虚拟主机路径下： /data/mnist 注意，客户端需要执行 polyaxon run -f job.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/data/cifar10': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/cifar10\n",
    "#data_path = '/data/cifar10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_local = './cifar10_log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型参数\n",
    "max_steps =100\n",
    "#train_dir   = data_path_local\n",
    "log_device_placement = False\n",
    "\n",
    "log_frequency = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', train_path_local,\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logging(log_level=None):\n",
    "    if log_level == 'INFO':\n",
    "        log_level = tf.logging.INFO\n",
    "    elif log_level == 'DEBUG':\n",
    "        log_level = tf.logging.DEBUG\n",
    "    elif log_level == 'WARN':\n",
    "        log_level = tf.logging.WARN\n",
    "    else:\n",
    "        log_level = 'INFO'\n",
    "\n",
    "    tf.logging.set_verbosity(log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_logging('DEBUG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型网络  tf.esstimator api\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    # Force input pipeline to CPU:0 to avoid operations sometimes ending up on\n",
    "    # GPU and resulting in a slow down.\n",
    "    with tf.device('/cpu:0'):\n",
    "      images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    class _LoggerHook(tf.train.SessionRunHook):\n",
    "      \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "      def begin(self):\n",
    "        self._step = -1\n",
    "        self._start_time = time.time()\n",
    "\n",
    "      def before_run(self, run_context):\n",
    "        self._step += 1\n",
    "        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "      def after_run(self, run_context, run_values):\n",
    "        if self._step % FLAGS.log_frequency == 0:\n",
    "          current_time = time.time()\n",
    "          duration = current_time - self._start_time\n",
    "          self._start_time = current_time\n",
    "\n",
    "          loss_value = run_values.results\n",
    "          examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "          sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                        'sec/batch)')\n",
    "          print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "        checkpoint_dir=FLAGS.train_dir,\n",
    "        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "               tf.train.NanTensorHook(loss),\n",
    "               _LoggerHook()],\n",
    "        config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "      while not mon_sess.should_stop():\n",
    "        mon_sess.run(train_op)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解决jupyter下cifar10 报错 UnrecognizedFlagError: Unknown command line flag 'f'\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.maybe_download_and_extract()\n",
    "\n",
    "if tf.gfile.Exists(FLAGS.train_dir):\n",
    "tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "\n",
    "tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhangkailin/code/tf.models/tutorials/image/cifar10/cifar10_input.py:158: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/zhangkailin/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/zhangkailin/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/zhangkailin/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/zhangkailin/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/zhangkailin/code/tf.models/tutorials/image/cifar10/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "WARNING:tensorflow:From /home/zhangkailin/code/tf.models/tutorials/image/cifar10/cifar10_input.py:126: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/zhangkailin/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./cifar10_log/model.ckpt.\n",
      "2019-03-31 12:46:32.470851: step 0, loss = 4.68 (84.4 examples/sec; 1.516 sec/batch)\n",
      "2019-03-31 12:46:32.895253: step 10, loss = 4.62 (3015.8 examples/sec; 0.042 sec/batch)\n",
      "2019-03-31 12:46:33.075878: step 20, loss = 4.50 (7086.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:33.252252: step 30, loss = 4.32 (7257.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:33.422646: step 40, loss = 4.29 (7512.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:33.607088: step 50, loss = 4.34 (6940.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:33.776024: step 60, loss = 4.44 (7576.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:33.957750: step 70, loss = 4.13 (7043.3 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:34.140451: step 80, loss = 4.07 (7006.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:34.319991: step 90, loss = 4.21 (7128.9 examples/sec; 0.018 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 43.803\n",
      "2019-03-31 12:46:34.755433: step 100, loss = 4.10 (2939.5 examples/sec; 0.044 sec/batch)\n",
      "2019-03-31 12:46:34.938349: step 110, loss = 4.00 (6998.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:35.118024: step 120, loss = 4.11 (7123.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:35.290868: step 130, loss = 4.01 (7405.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:35.477790: step 140, loss = 3.89 (6847.6 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:46:35.649723: step 150, loss = 4.14 (7445.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:35.833255: step 160, loss = 3.98 (6974.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:36.007685: step 170, loss = 3.96 (7342.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:36.185662: step 180, loss = 3.92 (7188.5 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:36.353583: step 190, loss = 3.85 (7622.8 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 49.6124\n",
      "2019-03-31 12:46:36.771456: step 200, loss = 3.75 (3063.2 examples/sec; 0.042 sec/batch)\n",
      "2019-03-31 12:46:36.975357: step 210, loss = 3.74 (6276.9 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:37.152606: step 220, loss = 3.91 (7221.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:37.359899: step 230, loss = 3.62 (6174.7 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:37.563183: step 240, loss = 3.84 (6296.6 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:37.764051: step 250, loss = 3.67 (6372.7 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:37.942625: step 260, loss = 3.57 (7167.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:38.114748: step 270, loss = 3.79 (7436.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:38.288798: step 280, loss = 3.79 (7354.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:38.462597: step 290, loss = 3.68 (7364.8 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 47.275\n",
      "2019-03-31 12:46:38.886073: step 300, loss = 3.61 (3022.7 examples/sec; 0.042 sec/batch)\n",
      "2019-03-31 12:46:39.065088: step 310, loss = 3.61 (7149.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:39.239979: step 320, loss = 3.49 (7318.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:39.415604: step 330, loss = 3.62 (7288.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:39.601794: step 340, loss = 3.46 (6874.4 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:46:39.762295: step 350, loss = 3.52 (7975.4 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:39.935536: step 360, loss = 3.65 (7388.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:40.109824: step 370, loss = 3.41 (7344.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:40.288743: step 380, loss = 3.39 (7153.9 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:40.461053: step 390, loss = 3.23 (7428.5 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 50.3452\n",
      "2019-03-31 12:46:40.870538: step 400, loss = 3.30 (3125.8 examples/sec; 0.041 sec/batch)\n",
      "2019-03-31 12:46:41.054667: step 410, loss = 3.26 (6951.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:41.229126: step 420, loss = 3.41 (7337.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:41.399384: step 430, loss = 3.23 (7520.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:41.581331: step 440, loss = 3.30 (7032.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:41.743591: step 450, loss = 3.10 (7888.8 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:41.921491: step 460, loss = 3.44 (7194.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:42.084816: step 470, loss = 3.10 (7837.1 examples/sec; 0.016 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31 12:46:42.267058: step 480, loss = 3.53 (7023.6 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:42.427942: step 490, loss = 3.18 (7956.3 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 50.4138\n",
      "2019-03-31 12:46:42.855181: step 500, loss = 3.10 (2995.9 examples/sec; 0.043 sec/batch)\n",
      "2019-03-31 12:46:43.031383: step 510, loss = 3.33 (7265.0 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:43.200507: step 520, loss = 3.18 (7568.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:43.378384: step 530, loss = 2.95 (7195.9 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:43.586950: step 540, loss = 3.03 (6137.0 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:43.807842: step 550, loss = 3.18 (5795.2 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:46:43.978373: step 560, loss = 3.01 (7505.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:44.146219: step 570, loss = 3.10 (7626.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:44.321524: step 580, loss = 3.01 (7301.5 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:44.488838: step 590, loss = 3.18 (7649.9 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 47.8421\n",
      "2019-03-31 12:46:44.946138: step 600, loss = 2.87 (2799.3 examples/sec; 0.046 sec/batch)\n",
      "2019-03-31 12:46:45.154375: step 610, loss = 2.94 (6146.0 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:45.351365: step 620, loss = 3.13 (6497.7 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:45.574462: step 630, loss = 3.01 (5737.5 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:46:45.781178: step 640, loss = 3.15 (6191.9 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:45.989059: step 650, loss = 2.93 (6157.3 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:46.189020: step 660, loss = 2.91 (6401.1 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:46.382406: step 670, loss = 2.98 (6619.4 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:46:46.580931: step 680, loss = 2.93 (6447.4 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:46.756291: step 690, loss = 2.82 (7298.9 examples/sec; 0.018 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 44.5423\n",
      "2019-03-31 12:46:47.189443: step 700, loss = 2.98 (2955.1 examples/sec; 0.043 sec/batch)\n",
      "2019-03-31 12:46:47.400644: step 710, loss = 3.03 (6060.8 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:46:47.580827: step 720, loss = 2.69 (7103.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:47.776313: step 730, loss = 2.95 (6548.0 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:46:48.013945: step 740, loss = 2.69 (5386.5 examples/sec; 0.024 sec/batch)\n",
      "2019-03-31 12:46:48.194591: step 750, loss = 2.70 (7085.6 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:48.362717: step 760, loss = 2.69 (7613.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:48.531276: step 770, loss = 2.87 (7593.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:48.774760: step 780, loss = 2.79 (5257.1 examples/sec; 0.024 sec/batch)\n",
      "2019-03-31 12:46:48.951707: step 790, loss = 2.70 (7233.6 examples/sec; 0.018 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 46.4516\n",
      "2019-03-31 12:46:49.342373: step 800, loss = 2.86 (3276.4 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:46:49.524831: step 810, loss = 2.68 (7015.3 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:49.694964: step 820, loss = 2.54 (7523.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:49.865700: step 830, loss = 2.65 (7497.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.035583: step 840, loss = 2.77 (7534.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.201723: step 850, loss = 2.76 (7704.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.372291: step 860, loss = 2.64 (7504.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.537851: step 870, loss = 2.52 (7731.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.711370: step 880, loss = 2.64 (7376.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:50.876411: step 890, loss = 2.58 (7755.3 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.0413\n",
      "2019-03-31 12:46:51.266218: step 900, loss = 2.64 (3284.0 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:46:51.448212: step 910, loss = 2.39 (7031.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:51.623381: step 920, loss = 2.41 (7307.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:51.787325: step 930, loss = 2.68 (7808.0 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:51.961595: step 940, loss = 2.61 (7344.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:52.134164: step 950, loss = 2.45 (7417.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:52.300326: step 960, loss = 2.51 (7703.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:52.466888: step 970, loss = 2.54 (7684.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:52.638700: step 980, loss = 2.41 (7450.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:52.808373: step 990, loss = 2.47 (7543.6 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.471\n",
      "2019-03-31 12:46:53.207118: step 1000, loss = 2.67 (3210.2 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:46:53.383151: step 1010, loss = 2.48 (7270.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:53.556181: step 1020, loss = 2.34 (7397.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:53.723746: step 1030, loss = 2.32 (7639.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:53.891085: step 1040, loss = 2.18 (7649.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:54.059864: step 1050, loss = 2.35 (7583.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:54.229432: step 1060, loss = 2.45 (7548.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:54.395828: step 1070, loss = 2.56 (7692.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:54.581499: step 1080, loss = 2.31 (6893.7 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:46:54.747911: step 1090, loss = 2.48 (7691.8 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.6139\n",
      "2019-03-31 12:46:55.144670: step 1100, loss = 2.30 (3226.1 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:46:55.319687: step 1110, loss = 2.24 (7314.0 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:55.486393: step 1120, loss = 2.36 (7678.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:55.652451: step 1130, loss = 2.47 (7708.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:55.831855: step 1140, loss = 2.36 (7134.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:55.995821: step 1150, loss = 2.22 (7806.2 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:56.170058: step 1160, loss = 2.13 (7346.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:56.340017: step 1170, loss = 2.28 (7531.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:56.518567: step 1180, loss = 2.03 (7168.9 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:56.688436: step 1190, loss = 2.32 (7534.9 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.8491\n",
      "2019-03-31 12:46:57.072745: step 1200, loss = 2.35 (3330.6 examples/sec; 0.038 sec/batch)\n",
      "2019-03-31 12:46:57.246513: step 1210, loss = 2.43 (7366.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:57.415375: step 1220, loss = 2.18 (7580.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:57.586630: step 1230, loss = 2.20 (7474.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:57.763099: step 1240, loss = 2.11 (7253.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:57.926829: step 1250, loss = 2.42 (7817.5 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:58.096712: step 1260, loss = 2.18 (7534.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:58.262824: step 1270, loss = 2.31 (7705.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:58.444362: step 1280, loss = 2.39 (7050.9 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:58.618504: step 1290, loss = 2.15 (7350.5 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.6168\n",
      "2019-03-31 12:46:59.010597: step 1300, loss = 2.16 (3264.6 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:46:59.191580: step 1310, loss = 2.16 (7072.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:46:59.362503: step 1320, loss = 2.07 (7489.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:59.526304: step 1330, loss = 2.28 (7813.9 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:46:59.695131: step 1340, loss = 1.97 (7581.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:46:59.866337: step 1350, loss = 2.17 (7476.2 examples/sec; 0.017 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31 12:47:00.040321: step 1360, loss = 2.25 (7356.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:00.202001: step 1370, loss = 2.02 (7917.2 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:00.370013: step 1380, loss = 2.17 (7618.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:00.535938: step 1390, loss = 2.11 (7714.0 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.991\n",
      "2019-03-31 12:47:00.933899: step 1400, loss = 2.16 (3216.5 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:47:01.107594: step 1410, loss = 2.00 (7368.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:01.273635: step 1420, loss = 1.85 (7709.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:01.438721: step 1430, loss = 2.05 (7753.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:01.605309: step 1440, loss = 2.00 (7683.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:01.772210: step 1450, loss = 1.94 (7669.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:01.940320: step 1460, loss = 1.98 (7614.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:02.106808: step 1470, loss = 2.03 (7688.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:02.273568: step 1480, loss = 2.12 (7675.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:02.439626: step 1490, loss = 1.93 (7707.9 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.9027\n",
      "2019-03-31 12:47:02.824591: step 1500, loss = 1.88 (3325.0 examples/sec; 0.038 sec/batch)\n",
      "2019-03-31 12:47:02.996279: step 1510, loss = 1.89 (7455.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:03.164140: step 1520, loss = 2.08 (7625.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:03.329910: step 1530, loss = 1.79 (7721.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:03.505866: step 1540, loss = 1.94 (7274.3 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:03.676208: step 1550, loss = 2.06 (7514.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:03.844336: step 1560, loss = 1.89 (7613.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:04.008966: step 1570, loss = 1.74 (7775.0 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:04.180120: step 1580, loss = 1.90 (7478.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:04.346878: step 1590, loss = 1.82 (7675.5 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.4961\n",
      "2019-03-31 12:47:04.728729: step 1600, loss = 2.03 (3352.1 examples/sec; 0.038 sec/batch)\n",
      "2019-03-31 12:47:04.897953: step 1610, loss = 1.81 (7564.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:05.082033: step 1620, loss = 1.90 (6953.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:05.250127: step 1630, loss = 1.83 (7615.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:05.419430: step 1640, loss = 2.06 (7560.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:05.584977: step 1650, loss = 1.91 (7732.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:05.754769: step 1660, loss = 1.82 (7538.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:05.936216: step 1670, loss = 1.95 (7054.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:06.105967: step 1680, loss = 1.75 (7540.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:06.269225: step 1690, loss = 1.72 (7840.3 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.717\n",
      "2019-03-31 12:47:06.663191: step 1700, loss = 1.86 (3249.2 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:47:06.835631: step 1710, loss = 1.92 (7422.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:07.003668: step 1720, loss = 1.83 (7617.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:07.173816: step 1730, loss = 1.76 (7523.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:07.339533: step 1740, loss = 1.84 (7724.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:07.505640: step 1750, loss = 1.81 (7705.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:07.685160: step 1760, loss = 1.64 (7130.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:07.854338: step 1770, loss = 1.83 (7565.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:08.023798: step 1780, loss = 1.85 (7553.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:08.194895: step 1790, loss = 1.74 (7481.1 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.7811\n",
      "2019-03-31 12:47:08.593881: step 1800, loss = 1.67 (3208.1 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:47:08.763669: step 1810, loss = 1.70 (7538.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:08.936236: step 1820, loss = 1.88 (7417.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:09.098961: step 1830, loss = 1.87 (7865.7 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:09.272180: step 1840, loss = 1.60 (7389.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:09.439441: step 1850, loss = 1.77 (7652.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:09.611986: step 1860, loss = 1.60 (7418.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:09.783484: step 1870, loss = 1.76 (7463.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:09.955981: step 1880, loss = 1.69 (7420.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:10.120505: step 1890, loss = 1.72 (7780.0 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.4361\n",
      "2019-03-31 12:47:10.501172: step 1900, loss = 1.72 (3362.6 examples/sec; 0.038 sec/batch)\n",
      "2019-03-31 12:47:10.672844: step 1910, loss = 1.60 (7455.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:10.842629: step 1920, loss = 1.87 (7538.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:11.006261: step 1930, loss = 1.63 (7822.4 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:11.172462: step 1940, loss = 1.52 (7701.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:11.340000: step 1950, loss = 1.76 (7640.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:11.517595: step 1960, loss = 1.57 (7207.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:11.682216: step 1970, loss = 1.65 (7775.4 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:11.852468: step 1980, loss = 1.70 (7518.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:12.016731: step 1990, loss = 1.70 (7792.0 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.5521\n",
      "2019-03-31 12:47:12.405989: step 2000, loss = 1.66 (3288.6 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:47:12.574543: step 2010, loss = 1.67 (7592.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:12.743797: step 2020, loss = 1.55 (7562.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:12.912818: step 2030, loss = 1.63 (7572.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.083223: step 2040, loss = 1.62 (7511.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.251719: step 2050, loss = 1.52 (7596.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.418415: step 2060, loss = 1.55 (7679.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.584671: step 2070, loss = 1.36 (7698.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.759358: step 2080, loss = 1.74 (7327.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:13.924022: step 2090, loss = 1.43 (7773.4 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.2314\n",
      "2019-03-31 12:47:14.318966: step 2100, loss = 1.62 (3241.0 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:47:14.494721: step 2110, loss = 1.62 (7283.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:14.659680: step 2120, loss = 1.68 (7759.5 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:14.821860: step 2130, loss = 1.62 (7892.2 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:14.987835: step 2140, loss = 1.61 (7712.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:15.153668: step 2150, loss = 1.46 (7718.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:15.322332: step 2160, loss = 1.63 (7589.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:15.488845: step 2170, loss = 1.63 (7687.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:15.657198: step 2180, loss = 1.54 (7603.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:15.822737: step 2190, loss = 1.58 (7732.0 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.8244\n",
      "2019-03-31 12:47:16.211225: step 2200, loss = 1.71 (3294.8 examples/sec; 0.039 sec/batch)\n",
      "2019-03-31 12:47:16.390797: step 2210, loss = 1.60 (7128.3 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:16.561313: step 2220, loss = 1.77 (7506.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:16.723504: step 2230, loss = 1.45 (7892.1 examples/sec; 0.016 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31 12:47:16.898577: step 2240, loss = 1.68 (7311.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:17.065056: step 2250, loss = 1.62 (7688.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:17.232799: step 2260, loss = 1.50 (7630.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:17.400664: step 2270, loss = 1.61 (7625.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:17.571373: step 2280, loss = 1.37 (7497.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:17.734745: step 2290, loss = 1.32 (7835.2 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.6161\n",
      "2019-03-31 12:47:18.118245: step 2300, loss = 1.67 (3338.0 examples/sec; 0.038 sec/batch)\n",
      "2019-03-31 12:47:18.291559: step 2310, loss = 1.40 (7383.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:18.461819: step 2320, loss = 1.55 (7518.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:18.628056: step 2330, loss = 1.48 (7699.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:18.797324: step 2340, loss = 1.55 (7561.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:18.966204: step 2350, loss = 1.37 (7579.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:19.132815: step 2360, loss = 1.53 (7682.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:19.297319: step 2370, loss = 1.38 (7781.0 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:19.471547: step 2380, loss = 1.49 (7346.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:19.638413: step 2390, loss = 1.70 (7670.8 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 52.066\n",
      "2019-03-31 12:47:20.034755: step 2400, loss = 1.37 (3230.0 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:47:20.218684: step 2410, loss = 1.51 (6957.0 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:20.381681: step 2420, loss = 1.39 (7852.5 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:20.555672: step 2430, loss = 1.39 (7356.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:20.721521: step 2440, loss = 1.22 (7718.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:20.884825: step 2450, loss = 1.38 (7837.8 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:21.053602: step 2460, loss = 1.48 (7584.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:21.221585: step 2470, loss = 1.44 (7619.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:21.393179: step 2480, loss = 1.52 (7460.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:21.557570: step 2490, loss = 1.39 (7785.6 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.9632\n",
      "2019-03-31 12:47:21.956909: step 2500, loss = 1.46 (3205.3 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:47:22.128219: step 2510, loss = 1.50 (7472.2 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:22.296079: step 2520, loss = 1.34 (7625.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:22.460305: step 2530, loss = 1.40 (7794.5 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:22.626065: step 2540, loss = 1.52 (7721.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:22.792886: step 2550, loss = 1.60 (7672.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:22.960648: step 2560, loss = 1.32 (7629.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:23.127193: step 2570, loss = 1.40 (7686.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:23.299394: step 2580, loss = 1.31 (7433.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:23.468684: step 2590, loss = 1.57 (7561.0 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 51.9473\n",
      "2019-03-31 12:47:23.882204: step 2600, loss = 1.46 (3095.4 examples/sec; 0.041 sec/batch)\n",
      "2019-03-31 12:47:24.052497: step 2610, loss = 1.24 (7516.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:24.227564: step 2620, loss = 1.29 (7311.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:24.393860: step 2630, loss = 1.32 (7697.7 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:24.567572: step 2640, loss = 1.17 (7368.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:24.743192: step 2650, loss = 1.40 (7288.4 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:24.921309: step 2660, loss = 1.44 (7186.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:25.098230: step 2670, loss = 1.43 (7235.0 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:25.267155: step 2680, loss = 1.33 (7578.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:25.443139: step 2690, loss = 1.45 (7272.8 examples/sec; 0.018 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 50.9295\n",
      "2019-03-31 12:47:25.846532: step 2700, loss = 1.37 (3173.0 examples/sec; 0.040 sec/batch)\n",
      "2019-03-31 12:47:26.022538: step 2710, loss = 1.33 (7272.5 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:26.196671: step 2720, loss = 1.32 (7351.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:26.369239: step 2730, loss = 1.37 (7417.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:26.535140: step 2740, loss = 1.60 (7715.4 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:26.715970: step 2750, loss = 1.37 (7078.8 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:26.891669: step 2760, loss = 1.34 (7285.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:27.073204: step 2770, loss = 1.56 (7050.9 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:27.246498: step 2780, loss = 1.35 (7386.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:27.407691: step 2790, loss = 1.06 (7941.2 examples/sec; 0.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 50.196\n",
      "2019-03-31 12:47:27.840870: step 2800, loss = 1.26 (2955.1 examples/sec; 0.043 sec/batch)\n",
      "2019-03-31 12:47:28.014023: step 2810, loss = 1.28 (7391.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:28.182613: step 2820, loss = 1.25 (7592.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:28.351062: step 2830, loss = 1.08 (7598.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:28.524273: step 2840, loss = 1.26 (7389.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:28.689170: step 2850, loss = 1.26 (7762.4 examples/sec; 0.016 sec/batch)\n",
      "2019-03-31 12:47:28.865377: step 2860, loss = 1.14 (7264.2 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:29.032090: step 2870, loss = 1.27 (7677.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:29.206912: step 2880, loss = 1.11 (7321.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:29.377356: step 2890, loss = 1.12 (7509.9 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 49.9458\n",
      "2019-03-31 12:47:29.843074: step 2900, loss = 1.25 (2748.6 examples/sec; 0.047 sec/batch)\n",
      "2019-03-31 12:47:30.035604: step 2910, loss = 1.30 (6647.1 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:47:30.219430: step 2920, loss = 1.52 (6963.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:30.434090: step 2930, loss = 1.36 (5962.8 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:30.649359: step 2940, loss = 1.32 (5945.9 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:47:30.856224: step 2950, loss = 1.26 (6187.6 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:31.057553: step 2960, loss = 1.45 (6358.2 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:31.258000: step 2970, loss = 1.22 (6385.5 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:31.454861: step 2980, loss = 1.31 (6501.9 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:31.672023: step 2990, loss = 1.30 (5894.4 examples/sec; 0.022 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 43.3691\n",
      "2019-03-31 12:47:32.152824: step 3000, loss = 1.32 (2662.3 examples/sec; 0.048 sec/batch)\n",
      "2019-03-31 12:47:32.351681: step 3010, loss = 1.15 (6436.2 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:32.566100: step 3020, loss = 1.21 (5970.0 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:32.779673: step 3030, loss = 1.27 (5993.4 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:32.987361: step 3040, loss = 1.14 (6163.9 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:33.196090: step 3050, loss = 1.21 (6131.0 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:33.410674: step 3060, loss = 1.14 (5965.0 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:33.608923: step 3070, loss = 1.31 (6456.6 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:33.827979: step 3080, loss = 1.34 (5843.6 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:47:34.030845: step 3090, loss = 1.19 (6309.3 examples/sec; 0.020 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 42.5138\n",
      "2019-03-31 12:47:34.499828: step 3100, loss = 1.25 (2729.3 examples/sec; 0.047 sec/batch)\n",
      "2019-03-31 12:47:34.674892: step 3110, loss = 1.09 (7311.4 examples/sec; 0.018 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31 12:47:34.855766: step 3120, loss = 1.34 (7076.5 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:35.065668: step 3130, loss = 1.31 (6098.4 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:35.299659: step 3140, loss = 1.29 (5470.3 examples/sec; 0.023 sec/batch)\n",
      "2019-03-31 12:47:35.533740: step 3150, loss = 1.15 (5468.1 examples/sec; 0.023 sec/batch)\n",
      "2019-03-31 12:47:35.755483: step 3160, loss = 1.06 (5773.4 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:47:35.968117: step 3170, loss = 1.20 (6018.5 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:36.181463: step 3180, loss = 1.27 (5999.6 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:36.358935: step 3190, loss = 1.16 (7212.7 examples/sec; 0.018 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 43.3796\n",
      "2019-03-31 12:47:36.806107: step 3200, loss = 1.38 (2862.7 examples/sec; 0.045 sec/batch)\n",
      "2019-03-31 12:47:36.982865: step 3210, loss = 1.29 (7240.1 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:37.154906: step 3220, loss = 1.26 (7439.8 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:37.322636: step 3230, loss = 1.32 (7631.5 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:37.491624: step 3240, loss = 1.38 (7574.6 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:37.670149: step 3250, loss = 1.17 (7169.6 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:37.852624: step 3260, loss = 1.21 (7015.0 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:38.024048: step 3270, loss = 1.19 (7467.1 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:38.222314: step 3280, loss = 1.13 (6455.8 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:38.393994: step 3290, loss = 1.12 (7455.7 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 48.5095\n",
      "2019-03-31 12:47:38.867086: step 3300, loss = 1.15 (2706.0 examples/sec; 0.047 sec/batch)\n",
      "2019-03-31 12:47:39.076951: step 3310, loss = 1.20 (6096.8 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:39.320021: step 3320, loss = 1.20 (5266.0 examples/sec; 0.024 sec/batch)\n",
      "2019-03-31 12:47:39.542761: step 3330, loss = 1.16 (5746.5 examples/sec; 0.022 sec/batch)\n",
      "2019-03-31 12:47:39.774991: step 3340, loss = 1.29 (5512.9 examples/sec; 0.023 sec/batch)\n",
      "2019-03-31 12:47:39.983222: step 3350, loss = 1.18 (6145.9 examples/sec; 0.021 sec/batch)\n",
      "2019-03-31 12:47:40.220881: step 3360, loss = 1.29 (5385.9 examples/sec; 0.024 sec/batch)\n",
      "2019-03-31 12:47:40.494676: step 3370, loss = 1.13 (4675.0 examples/sec; 0.027 sec/batch)\n",
      "2019-03-31 12:47:40.686734: step 3380, loss = 1.37 (6664.8 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:47:40.856293: step 3390, loss = 1.25 (7548.7 examples/sec; 0.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 40.7907\n",
      "2019-03-31 12:47:41.317149: step 3400, loss = 1.32 (2777.5 examples/sec; 0.046 sec/batch)\n",
      "2019-03-31 12:47:41.503151: step 3410, loss = 1.27 (6881.3 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:47:41.698035: step 3420, loss = 1.36 (6570.0 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:47:41.866834: step 3430, loss = 1.10 (7580.3 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:42.065266: step 3440, loss = 1.02 (6450.5 examples/sec; 0.020 sec/batch)\n",
      "2019-03-31 12:47:42.257776: step 3450, loss = 1.04 (6649.1 examples/sec; 0.019 sec/batch)\n",
      "2019-03-31 12:47:42.437180: step 3460, loss = 1.10 (7134.7 examples/sec; 0.018 sec/batch)\n",
      "2019-03-31 12:47:42.608306: step 3470, loss = 1.20 (7479.9 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:42.777302: step 3480, loss = 1.10 (7574.0 examples/sec; 0.017 sec/batch)\n",
      "2019-03-31 12:47:42.959819: step 3490, loss = 1.17 (7012.9 examples/sec; 0.018 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fe61aa895a98>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m             log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfgpu12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t    model.ckpt-0.data-00001-of-00002\r\n",
      "events.out.tfevents.1554007577.zkl  model.ckpt-0.index\r\n",
      "graph.pbtxt\t\t\t    model.ckpt-0.meta\r\n",
      "model.ckpt-0.data-00000-of-00002\r\n"
     ]
    }
   ],
   "source": [
    "!ls {train_path_local}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tfgpu12",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
