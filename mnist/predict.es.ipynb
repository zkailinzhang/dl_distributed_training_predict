{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import struct \n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\r\n",
      "README.md\r\n",
      "Untitled-1\r\n",
      "Untitled-1p\r\n",
      "Untitled.ipynb\r\n",
      "bug-fix.ipynb\r\n",
      "ci\r\n",
      "download_data.py\r\n",
      "latest_helper.yml\r\n",
      "linear_regression.1.ipynb\r\n",
      "linear_regression.house.price.ipynb\r\n",
      "lnv_build.yml\r\n",
      "log\r\n",
      "lr-13.png\r\n",
      "mnist1\r\n",
      "model.ops\r\n",
      "model.py\r\n",
      "model_tf.py\r\n",
      "modelp\r\n",
      "polyaxonfile.yml\r\n",
      "polyaxonfile_declarations.yml\r\n",
      "polyaxonfile_hyperparams.yml\r\n",
      "polyaxonfile_hyperparams_bo.yml\r\n",
      "polyaxonfile_hyperparams_early_stopping.yml\r\n",
      "polyaxonfile_hyperparams_grid.yml\r\n",
      "polyaxonfile_hyperparams_hyperband.yml\r\n",
      "polyaxonfile_job.yml\r\n",
      "polyaxonfile_notebook.yml\r\n",
      "polyaxonfile_tensorboard.yml\r\n",
      "predict.ckpt.py\r\n",
      "predict.es.ipynb\r\n",
      "predict.es.py\r\n",
      "sgd_classifier.ipynb\r\n",
      "t.ipynb\r\n",
      "test.py\r\n",
      "testcomment.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  数据路径存在虚拟主机路径下： /data/mnist 注意，客户端需要执行 polyaxon run -f job.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx1-ubyte\t   t10k-labels-idx1-ubyte.gz\r\n",
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte.gz\r\n",
      "t10k-images-idx3-ubyte.gz  train-labels-idx1-ubyte.gz\r\n",
      "t10k-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/mnist/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = '/data/mnist/'\n",
    "test_images\n",
    "os.system('gunzip -c {} > {}'.format(test_images+ 't10k-images-idx3-ubyte.gz',test_images +'t10k-images-idx3-ubyte'))\n",
    "os.system('gunzip -c {} > {}'.format(test_images + 't10k-labels-idx1-ubyte.gz',test_images +'t10k-labels-idx1-ubyte'))\n",
    "test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#加载数据的路径\n",
    "#path='./dataset/mnist/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def load_mnist_train(path, kind='train'):    \n",
    "    labels_path = os.path.join(path,'%s-labels-idx1-ubyte'% kind)\n",
    "    images_path = os.path.join(path,'%s-images-idx3-ubyte'% kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_mnist_test(images_path,labels_path):\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "    return images, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/mnist/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path= os.path.join(test_images,'t10k-images-idx3-ubyte')\n",
    "test_labels_path= os.path.join(test_images, 't10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_images=[]\n",
    "test_labels=[]\n",
    "test_images,test_labels=load_mnist_test(test_images_path,test_labels_path)\n",
    "print(np.shape(test_images),np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90aac9fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_random = test_images[0,:].reshape(28,28)\n",
    "plt.imshow(img_random,cmap=plt.cm.gray)\n",
    "plt.title(test_labels[0])\n",
    "plt.Text(0.5,1,'7')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型路径存在虚拟主机路径下： /outputs/root/quick-start1/experiments/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/outputs/root//quick-start1/experiments/5/\n"
     ]
    }
   ],
   "source": [
    "modelpathpre = '/outputs/root//'\n",
    "experiment  = 'quick-start1/'\n",
    "exp_num = 'experiments/5/'\n",
    "\n",
    "modelpath = modelpathpre + experiment  + exp_num\n",
    "print(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#没有？\n",
    "asda =os.system('ls {}'.format(modelpath))\n",
    "asda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "eval\r\n",
      "events.out.tfevents.1553656058.plx-d9f55b96b11b470083a5362839007717-master-0\r\n",
      "graph.pbtxt\r\n",
      "model.ckpt-1.data-00000-of-00001\r\n",
      "model.ckpt-1.index\r\n",
      "model.ckpt-1.meta\r\n",
      "model.ckpt-430.data-00000-of-00001\r\n",
      "model.ckpt-430.index\r\n",
      "model.ckpt-430.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls {modelpath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重点来了，加载模型，读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.estimator  需要写网络的  \n",
    "#用estimator加载\n",
    "mode = tf.estimator.ModeKeys.PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fn(dropout):\n",
    "    \"\"\"Create a `model_fn` compatible with tensorflow estimator based on hyperparams.\"\"\"\n",
    "\n",
    "    def get_network(x_dict, is_training):\n",
    "        with tf.variable_scope('network'):\n",
    "            x = x_dict['images']\n",
    "            x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "            conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "            conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "            conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "            conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "            fc1 = tf.contrib.layers.flatten(conv2)\n",
    "            fc1 = tf.layers.dense(fc1, 1024)\n",
    "            fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "            out = tf.layers.dense(fc1, 10)\n",
    "        return out\n",
    "\n",
    "    def model_fn(features, labels, mode):\n",
    "        is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "        #is_training = 0\n",
    "        results = get_network(features, is_training=is_training)\n",
    "\n",
    "        predictions = tf.argmax(results, axis=1)\n",
    "\n",
    "        # Return prediction\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "#             return tf.estimator.EstimatorSpec(mode, predictions=\n",
    "#                                               {'predict':tf.argmax(predictions,1)})\n",
    "\n",
    "\n",
    "                # Define loss\n",
    "        loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=results, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # Evaluation metrics\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions)\n",
    "        precision = tf.metrics.precision(labels=labels, predictions=predictions)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss_op,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={'accuracy': accuracy, 'precision': precision})\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_master': '', '_task_id': 0, '_session_config': None, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_service': None, '_task_type': 'worker', '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f90a62739b0>, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/outputs/root//quick-start1/experiments/5/'}\n"
     ]
    }
   ],
   "source": [
    "estim = tf.estimator.Estimator(get_model_fn(dropout=0.),model_dir=modelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (1, 784)\n"
     ]
    }
   ],
   "source": [
    "img_random2 = img_random.reshape(1,784)\n",
    "img_random2 =img_random2.astype(np.float32)\n",
    "print(img_random2.dtype,np.shape(img_random2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn2 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': img_random2},\n",
    "    y=None,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "INFO:tensorflow:Restoring parameters from /outputs/root//quick-start1/experiments/5/model.ckpt-430\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#TypeError: 'str' object is not callable 一直报这个错误\n",
    "\n",
    "pred = estim.predict(input_fn=input_fn2)\n",
    "print(type(pred))\n",
    "for p in pred:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
